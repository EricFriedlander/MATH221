---
title: "17 Inference For Comparing Two Proportions"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(openintro)
library(tidyverse)
library(infer)

fish_oil <- fish_oil_18[['major_cardio_event']]

p_fo <- 386/(386+12547)
p_p <- 419/(419+12519)


p_diff <- p_fo - p_p

p_pool <- (39+26)/90

SE <- sqrt(p_fo*(1-p_fo)/(386+12547) + p_p*(1-p_p)/(419+12519) )

p_T <- 26/(26+14)
p_C <- 39/(39+11)
  
nT <- (26+14)
nC <- (29+11)
  
z <- (p_T- p_C) / sqrt(p_pool*(1-p_pool)*(1/nT+1/nC))

z_star <- qnorm(.975, mean=0, sd=1)

knitr::opts_chunk$set(echo = FALSE)
```


## Fish Oil on Heart Attacks

A 5-year experiment was conducted to evaluate the effectiveness of fish oils on reducing heart attacks, where each subject was randomized into one of two treatment groups. We’ll consider the data stored in the contingency table `fish_oil`. Take a look around the data set below. 

```{r sandbox, exercise=TRUE}
fish_oil
```

Your task is conduct a 95% confidence interval for the difference in the rate of major cardiac events between those in the `fish_oil` and `placebo` groups. Notice that our data meets the success-failure condition so we can use the CLT. If you feel up to it, try and do it all in the console below. If you don't feel comfortable doing this the remaining consoles will walk you through the steps.

```{r ci-advanced, exercise=TRUE}

```

Remember that confidence intervals take the form $\hat{p}_1-\hat{p}_2\pm z^*\times SE$. Let first compute $\hat{p}_1-\hat{p}_2$, our point estimate:

```{r point_est, exercise=TRUE}

```

```{r point_est-hint-1}
p_fo <- _____
p_p <- _____

p_diff <- ______ - ______

p_fo
p_p
p_diff
```

```{r point_est-hint-2}
p_fo <- _____
p_p <- _____

p_diff <- p_fo - p_p

p_fo
p_p
p_diff
```

```{r point_est-hint-3}
p_fo <- 386/(386+12547)
p_p <- 419/(419+12519)


p_diff <- p_fo - p_p

p_fo
p_p
p_diff
```

Now that we have our point estimate, compute the standard error (technically the estimate of the standard error):

```{r standard-err, exercise=TRUE}

```

```{r standard-err-hint-1}
SE <- sqrt(_____*(1-_____)/_____ + _____*(1-_____)/_____ )
SE
```

```{r standard-err-hint-2}
SE <- sqrt(p_fo*(1-p_fo)/(386+12547) + _____*(1-_____)/_____ )
SE
```

```{r standard-err-hint-3}
SE <- sqrt(p_fo*(1-p_fo)/(386+12547) + p_p*(1-p_p)/(419+12519) )
SE
```

Compute $z^*$ for a 95% confidence interval:

```{r z-star, exercise=TRUE}

```

```{r z-star-hint-1}
z_star <- qnorm(_____, _____, _____)
z_star
```

```{r z-star-hint-2}
z_star <- qnorm(_____, mean=_____, sd=_____)
z_star
```

```{r z-star-hint-3}
z_star <- qnorm(.975, mean=0, sd=1)
z_star
```

Now that we have all the ingredients that we need, compute the confidence interval:

```{r con-int, exercise=TRUE}

```

```{r con-int-hint-1}
_____ - _____ * _____
_____ + _____ * _____
```

```{r con-int-hint-2}
p_diff - z_star * SE
p_diff + z_star * SE
```


So our 95% confidence interval is (-.68%, .17%).


## CPR and Blood Thinners

An experiment consisted of two treatments on patients who underwent CPR for a heart attack and were subsequently admitted to a hospital. Each patient was randomly assigned to either receive a blood thinner (treatment group) or not receive a blood thinner (control group). The outcome variable of interest was whether the patient survived for at least 24 hours. The data is stored in `cpr`:

```{r sandy, exercise=TRUE}

```

Your task is to test whether giving patients a blood thinner impacts mortality. If you feel up to it, try and do it all in the console below. This includes selecting your own significance level. If you don't feel comfortable doing this the remaining consoles will walk you through the steps.

```{r advanced, exercise=TRUE}

```


Call the mortality rate of the population that receives the treatment $p_T$ and the mortality rate of those who do not $p_C$. On a sheet of paper or in the console, write down what you think your null and alternative hypotheses are:

```{r hypotheses, exercise=TRUE}
# H0:
# HA:
```


```{r hypotheses-solution}
# H0: p_T - p_C = 0
# HA: p_T - p_C ≄ 0
```

Create a contingency table:

```{r cont_tab, exercise=TRUE}

```

```{r cont_tab-hint-1}
______ %>% 
  _____ %>% 
  ______
```

```{r cont_tab-hint-2}
cpr %>% 
  count(_____, ______) %>% 
  pivot_wider(names_from=______, values_from = _____)
```

```{r cont_tab-hint-3}
cpr %>% 
  count(group, outcome) %>% 
  pivot_wider(names_from=group, values_from = n)
```

Compute $\hat{p}_{\textit{pool}}$

```{r pool, exercise=TRUE}

```

```{r pool-hint-1}
p_pool <- ____/______
```

```{r pool-hint-2}
p_pool <- (39+26)/90
p_pool
```


Does this test/data meet the success-failure criterion?

```{r s-f, exercise=TRUE}

```

```{r s-f-hint-1}
p_pool * ____
(1-p_pool) * ____
p_pool * ____
(1-p_pool) * ____
```

```{r s-f-hint-2}
p_pool * (39+11)
(1-p_pool) * (39+11)
p_pool * (26+14)
(1-p_pool) * (26+14)

# Since all these values are above 10 we satisfy the success-failure criterion
```

Compute the test statistic (z-score):

```{r test-statistic, exercise=TRUE}

```

```{r test-statistic-hint-1}
p_T <- _____
p_C <- _____
  
nT <- _____
nC <- _____
  
z <- _____
z
```

```{r test-statistic-hint-2}
p_T <- 26/(26+14)
p_C <- 39/(39+11)
  
nT <- (26+14)
nC <- (29+11)
  
z <- _____
z
```

```{r test-statistic-hint-3}
p_T <- 26/(26+14)
p_C <- 39/(39+11)
  
nT <- (26+14)
nC <- (29+11)
  
z <- (p_T- p_C) / sqrt(p_pool*(1-p_pool)*(1/nT+1/nC))
z
```

Use the `normTail` function to display the region of the standard normal distribution corresponding to your p-value:

```{r z, exercise=TRUE}

```

```{r z-hint-1}
normTail(____, ____, _____, ____)
```

```{r z-hint-2}
normTail(m=_____, s=____, L=_____, U=_____)
```

```{r z-hint-3}

normTail(m=0, s=1,  L=_____, U=_____)
```

```{r z-hint-4}
normTail(m=0, s=1, L=z, U=-z)
```

Compute your p-value:

```{r p-val, exercise=TRUE}

```

```{r p-val-hint-1}
2*pnorm(____, ____, ____)
```

```{r p-val-hint-2}
2*pnorm(____, mean = ____, sd = ____)
```

```{r p-val-hint-3}
2*pnorm(z, mean = 0, sd = 1)
```

```{r q-1}
question_radio(
"Would is the result of this hypothesis test with a significance level of $\\alpha = 0.05$",
answer("Fail to Reject the Null Hypothesis", correct=TRUE),
answer("Reject the null hypothesis"),
allow_retry=TRUE
)
```



## Is yawning contagious?

An experiment conducted by the MythBusters, a science entertainment TV program on the Discovery Channel, tested if a person can be subconsciously influenced into yawning if another person near them yawns. 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a group where there wasn't a person yawning near them (control). The data is stored in the data frame `yawn`, you can check it out here:

```{r sandbox-3, exercise=TRUE}

```

As a lab assistant on the show, you're assigned to test whether whether yawning is contageous. I.e. does being near someone who yawns, increase someones probability of yawning. In the console below or on a separate sheet of paper, state the null and alternative hypotheses:

```{r boot-hyps, excise=TRUE}

```

```{r boot-hyps-solution}
# H0: p_treatment - p_control = 0
# HA: p_treatment - p_control > 0
```

In the console below, determine whether this data meets the *success-failure* condition (you may assume that the observations are independent):

```{r clt-1, exercise=TRUE}

```

```{r clt-1-hint-1}
p_pooled <- _____

_____
_____
_____
_____
```

```{r clt-1-hint-2}
p_pooled <- (10+4)/(12+4+24+10)

_____
_____
_____
_____
```

```{r clt-1-hint-3}
p_pooled <- (10+4)/(12+4+24+10)

p_pooled * _____
p_pooled * _____
(1-p_pooled) * _____
(1-p_pooled) * _____
```

```{r clt-1-hint-4}
p_pooled <- (10+4)/(12+4+24+10)

p_pooled * (12+4)
p_pooled * (24+10)
(1-p_pooled) * (12+4)
(1-p_pooled) * (24+10)
```

```{r q-2}
question_radio(
"Can you apply the CLT to perform a hypothesis test on this data",
answer("Yes, the independence and success-failure conditions are both met"),
answer("No, the independence condition is not met"),
answer("No, the success-failure condition is not met", correct=TRUE),
answer("No, neither the independence or success-failure conditions are met"),
allow_retry=TRUE
)
```


Compute the observed test statistic from the data using the infer package. Call the result `test_stat`:

```{r observed, exercise=TRUE}

```

```{r observed-hint-1}
test_stat <- yawn %>%
  specify(_____) %>%
  calculate(_____)
test_stat
```

```{r observed-hint-2}
test_stat <- yawn %>%
  specify(result ~ group, success = "yawn") %>%
  calculate(stat = "diff in props", order = c("trmt", "ctrl"))
test_stat
```

Use the infer package to generate the 10,000 replicate approximating the null distribution of this test and then visualize this distribution. Store the replicates in a data frame called `null_distribution`:

```{r reps-ht, exercise=TRUE}

```

```{r reps-ht-hint-1}
null_distribution <-_____ %>%
  specify(_____) %>%
  hypothesize(_____) %>%
  generate(_____) %>%
  calculate(_____)

null_distribution %>%
  visualize()
```

```{r reps-ht-hint-2}
null_distribution <-yawn %>%
  specify(______, success = "_____") %>%
  hypothesize(null = "_____") %>%
  generate(reps = _____, type="_____") %>%
  calculate(stat="_____", order = _____))

null_distribution %>%
  visualize()
```

```{r reps-ht-hint-3}
null_distribution <-yawn %>%
  specify(result ~ group, success = "yawn") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 10000, type="permute") %>%
  calculate(stat="diff in props", order = c("trmt", "ctrl"))

null_distribution %>%
  visualize()
```

In the console below, compute the p-value of this test and use the `shade_p_value` function to visualize the p-value:

```{r final-p-value-setup}
test_stat <- yawn %>%
  specify(result ~ group, success = "yawn") %>%
  calculate(stat = "diff in props", order = c("trmt", "ctrl"))

null_distribution <-yawn %>%
  specify(result ~ group, success = "yawn") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 10000, type="permute") %>%
  calculate(stat="diff in props", order = c("trmt", "ctrl"))
```

```{r final-p-value, exercise=TRUE}

```

```{r final-p-value-hint-1}
null_distribution %>%
  get_p_value(_____)

null_distribution %>%
  visualize()) +
  shade_p_value(_____)
```

```{r final-p-value-hint-2}
null_distribution %>%
  get_p_value(_____, direction="_____")

null_distribution %>%
  visualize() +
  shade_p_value(_____, direction = "_____")
```

```{r final-p-value-hint-3}
null_distribution %>%
  get_p_value(test_stat, direction="right")

null_distribution %>%
  visualize() +
  shade_p_value(test_stat, direction = "right")
```


```{r named}
question_radio(
  "What is the result of this test if we used a significance level of 0.05?",
  answer("Fail to reject the null", correct=TRUE),
  answer("Reject the null", correct=TRUE),
  allow_retry = TRUE
)
```

## Does acupunture help with migraines?

You're a researcher studying migraines. Your research group would like to investigate whether acupunture can prevent migraines. The results of an experiment involving acupuncture and sham acupuncture (as placebo) in the treatment of migraines is contained in the data frame `migraine`. Take a look at it here:

```{r sandbox-5, exercise=TRUE}

```

You decide to construct a 90% confidence interval for the improvement in the rate of migraines for those who receive acupunture. I.e. you'd like to create a confidence interval for $p_{A}-p_{C}$, where $p_{A}$ is the proportion of patients who are pain-free after receiving acupunture and $p_C$ is the proportion from those who don't. In the console below, determine whether this data meets the *success-failure* condition (you may assume that the observations are independent):

```{r clt-2, exercise=TRUE}

```

```{r clt-2-hint-1}
migraine %>% 
  count(_____, _____) %>% 
  pivot_wider(_____, _____)
```

```{r clt-2-hint-2}
migraine %>% 
  count(_____, _____) %>% 
  pivot_wider(names_from = _____, values_from = _____)
```

```{r clt-2-hint-3}
migraine %>% 
  count(pain_free, group) %>% 
  pivot_wider(names_from = group, values_from = n)
```

```{r q-3}
question_radio(
"Can you apply the CLT to this data",
answer("Yes, the independence and success-failure conditions are both met"),
answer("No, the independence condition is not met"),
answer("No, the success-failure condition is not met", correct=TRUE),
answer("No, neither the independence or success-failure conditions are met"),
allow_retry=TRUE
)
```

In the console below, if you feel confident (once again... PUN INTENDED!!!!), construct a 90% bootstrapped confidence interval for $p_A-p_C$. If you don't yet feel comfortable, walk through the steps below:

```{r advanced-boot-ci, exercise=TRUE}

```

First, compute a point estimate (use the infer package):

```{r point-est-boot, exercise=TRUE}

```

```{r point-est-boot-hint-1}
migraine %>%
 specify(_____) %>%
 calculate(_____)
```

```{r point-est-boot-hint-2}
migraine %>%
 specify(_____ ~ _____, success = "_____") %>%
 calculate(stat = "_____", order = _____)
```

```{r point-est-boot-hint-3}
migraine %>%
 specify(pain_free ~ group, success = "yes") %>%
 calculate(stat = "diff in props", order = c("treatment", "control"))
```

Use the infer package to generate the 10,000 bootstrapped replicates of the data to approximate the sampling distribution (call the resulting data frame `sampling_dist`) and then visualize this distribution:

```{r sampling-dist-3, exercise=TRUE}

```

```{r sampling-dist-3-hint-1}
sampling_dist <- _____ %>% 
  specify(_____) %>% 
  generate(_____) %>% 
  calculate(_____)

sampling_dist %>% 
  _____
```

```{r sampling-dist-3-hint-2}
sampling_dist <- migraine %>% 
  specify(_____ ~ _____, success = "_____") %>%
  generate(reps = _____, type = ______)
 calculate(stat = "_____", order = _____)

sampling_dist %>% 
  visualize()
```

```{r sampling-dist-3-hint-3}
sampling_dist <- migraine %>% 
  specify(pain_free ~ group, success = "yes") %>%
  generate(reps = 10000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("treatment", "control"))

sampling_dist %>% 
  visualize()
```

Now use the infer package to compute a 90% confidence interval based on this bootstrapped distribution and plot the shaded region using the `shade_ci` function:

```{r ci-boot-setup}
set.seed(1988)
sampling_dist <- migraine %>% 
  specify(pain_free ~ group, success = "yes") %>%
  generate(reps = 10000, type = "bootstrap") %>% 
  calculate(stat = "diff in props", order = c("treatment", "control"))
```

```{r ci-boot, exercise=TRUE}
 
```

```{r ci-boot-hint-1}
ci <- _____ %>% 
  _____(_____ = ____)
ci

_____ %>% 
 _____ +  
  _____(_____)
```

```{r ci-boot-hint-2}
ci <- _____ %>% 
  get_ci(_____ = _____)
ci

sampling_dist %>% 
  visualize() +  
  shade_ci(_____)
```

```{r ci-boot-hint-3}
ci <- sampling_dist %>% 
  get_ci(level = 0.9)
ci

sampling_dist %>% 
  visualize() +  
  shade_ci(ci)
```

What is our point estimate and 90% confidence interval:

```{r boot-ci-final, exercise=TRUE}
# 
```

```{r boot-ci-final-solution}
# Our point estimate is 18.9% with a 90% confidence interval of 7.37% to 31.0%. 
```

(Sample exam question): If you were to perform this exactly analysis again, would you get the exact same confidence interval?

```{r boot-q, exercise=TRUE}
#
```

```{r boot-q-solution}
# No, the bootstrapping portion of this analysis has some randomness built in so we will get a slightly different answer each time we simulate the sampling distribution which will lead to slightly different confidence intervals each time.
```


## Malaria vaccine effectiveness, confidence interval.

With no currently licensed vaccines to inhibit malaria, good news was welcomed with a recent study reporting long-awaited vaccine success for children in Burkina Faso. With 450 children randomized to either one of two different doses of the malaria vaccine or a control vaccine, 89 of 292 malaria vaccine and 106 out of 147 control vaccine children contracted malaria within 12 months after the treatment. (Datoo et al, 2021)

```{r}
library(tidyverse)
library(infer)

malaria <- tibble(
  vaccine = c(rep("malaria", 292), rep("control", 147)),
  outcome = c(
    rep("sick", 89), rep("healthy", 203),
    rep("sick", 106), rep("healthy", 41)
  )
)

set.seed(47)
malaria %>%
  specify(outcome ~ vaccine, success = "sick") %>%
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "diff in props", order = c("malaria", "control")) %>%
  ggplot(aes(x = stat)) +
  geom_histogram(fill = IMSCOL["green", "full"], binwidth = 0.02) +
  labs(
    title = "1,000 bootstrapped differences",
    x = "Difference in bootstrapped proportions\n(malaria - control)",
    y = "Count"
  )
```

a. Consider the bootstrap distribution of difference in sample proportions of children who contracted malaria (malaria vaccine minus control vaccine) in 1000 bootstrap repetitions as above. Estimate the standard error of the difference in sample proportions, as seen in the histogram.
    
b. Using the standard error from the bootstrap distribution, find a 95% bootstrap SE confidence interval for the true difference in proportion of children who contract malaria (malaria vaccine minus control vaccine) in the population. In this case, use a normal distribution and just estimate the SE based on the repetitions. Interpret the interval in the context of the problem.
    
c. Using the entire bootstrap distribution, estimate a 95% bootstrap percentile confidence interval for the true difference in proportion of children who contract malaria (malaria vaccine minus control vaccine) in the population. Interpret the interval in the context of the problem.


```{r mal-1, exercise=TRUE}
# a)

# b)

# c)
```

```{r mal-1-solution}
# a) The bootstrapped difference in proportions appear to vary from about -0.5 to -0.37, resulting in a standard error of roughly 0.03.

# b) The bootstrap SE confidence interval is:phat_{malaria} - phat_{control} ±1.96⋅SE →−0.416±1.96⋅0.03→(−0.475,−0.357). We are 95% confident that the true proportion of children who contract malaria is between 35.7 and 47.5 percentage points higher in the control vaccine group than in the malaria vaccine group.

# c) The bootstrap distribution indicates that the bootstrap differences vary from roughly -0.5 to -0.37. We are 95% confident that the true proportion of children who contract malaria is between 37 and 50 percentage points higher in the control vaccine group than in the malaria vaccine group.
```
    

## Malaria vaccine effectiveness, hypothesis test.
With no currently licensed vaccines to inhibit malaria, good news was welcomed with a recent study reporting long-awaited vaccine success for children in Burkina Faso. With 450 children randomized to either one of two different doses of the malaria vaccine or a control vaccine, 89 of 292 malaria vaccine and 106 out of 147 control vaccine children contracted malaria within 12 months after the treatment. (Datoo et al, 2021)

```{r}
library(tidyverse)
library(infer)
malaria <- tibble(
  vaccine = c(rep("malaria", 292), rep("control", 147)),
  outcome = c(
    rep("sick", 89), rep("healthy", 203),
    rep("sick", 106), rep("healthy", 41)
  )
)
set.seed(47)
malaria %>%
  specify(outcome ~ vaccine, success = "sick") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("malaria", "control")) %>%
  ggplot(aes(x = stat)) +
  geom_histogram(fill = IMSCOL["green", "full"], binwidth = 0.02) +
  labs(
    title = "1,000 randomized differences",
    x = "Difference in randomized proportions\n(malaria - control)",
    y = "Count"
  )
```

a. In both words and symbols provide the parameter and statistic of interest for this study. Do you know the numerical value of either the parameter or statisic of interest? If so, provide the numerical value.

b. The histogram above provides the sampling distribution (under randomization) for $\hat{p}_{malaria} - \hat{p}_{control}$ under repeated null randomizations ($\hat{p}$ is the proportion of children in the sample who contracted malaria). Estimate the standard error of $\hat{p}_{malaria} - \hat{p}_{control}$ based on the randomization histogram.

c. Consider the hypothesis test constructed to show a lower proportion of children contracting malaria on the malaria vaccine as compared to the control vaccine. Write out the null and alternative hypotheses, estimate a p-value using the randomization histogram, and conclude the test in the context of the problem.

```{r mal-2, exercise=TRUE}
# a)

# b)

# c)
```

```{r mal-2-solution}
# a) The parameter is the true difference in proportions of children who will contract malaria after being on the malaria vaccine as compared to the control vaccine: pmalaria−pcontrol. The statistic of interest is the proportion of malaria vaccine childern in the sample who got malaria as compared to the proportion of control vaccine children in the sample who got malaria: p̂ malaria−p̂ control. The parameter is unknown, but the statistic is computed to be p̂ malaria−p̂ control=89/292−106/147=−0.416.

# b) The variability of p̂ malaria−p̂ control from sample to sample seems to spread from about -0.1 to about 0.1, leading to a standard error of p̂ malaria−p̂ control which is roughly 0.05.

# c) The null hypothesis is that the true proportion of children who contract malaria will not be different across the two vaccine groups (malaria vaccine and control vaccine). The alternative hypothesis is that the malaria vaccine group will have a lower proportion of children who contract malaria. H0:pmalaria−pcontrol=0;, HA:pmalaria−pcontrol<0. The observed difference of -0.416 is no where near the randomization differences, indicating that the observed data are not consistent with differences in sample proportions constructed through randomizing the observed data. The p-value is very small, and the null hypothesis can be rejected. The malaria vaccine is more effective at controlling the rate of contracting malaria than the control vaccine.
```

## Sleep deprivation, CA vs. OR, confidence interval.

According to a report on sleep deprivation by the Centers for Disease Control and Prevention, the proportion of California residents who reported insufficient rest or sleep during each of the preceding 30 days is 8.0%, while this proportion is 8.8% for Oregon residents. These data are based on simple random samples of 11,545 California and 4,691 Oregon residents. Calculate a 95% confidence interval for the difference between the proportions of Californians and Oregonians who are sleep deprived and interpret it in context of the data. (CDC 2008)

```{r sleep-1, exercise=TRUE}
# 
```

```{r sleep-1-solution}
# Before calculating the confidence interval we should check that the conditions are satisfied.

# Since the data are randomly sampled, we can assume that the observations are independent. The success-failure condition is clearly met. Therefore, the difference in proportions is expected to be approximately normal. A 95% confidence interval for the difference between the population proportions is  (-.017, .001).

# We are 95% confident that the difference between the proportions of Californians and Oregonians who are sleep deprived is between -1.7% and 0.1%. In other words, we are 95% confident that 1.7% less to 0.1% more Californians than Oregonians are sleep deprived.
```


## Sleep deprivation, CA vs. OR, hypothesis test.

A CDC report on sleep deprivation rates shows that the proportion of California residents who reported insufficient rest or sleep during each of the preceding 30 days is 8.0%, while this proportion is 8.8% for Oregon residents. These data are based on simple random samples of 11,545 California and 4,691 Oregon residents.

a. Conduct a hypothesis test to determine if these data provide strong evidence that the rate of sleep deprivation is different for the two states. Use $\alpha=0.05$. (Reminder: Check conditions)

b. It is possible the conclusion of the test in part (a) is incorrect. If this is the case, what type of error was made?

```{r sleep-2, exercise=TRUE}
# a)

# b)
```

```{r sleep-2-solution}
# a) The hypotheses are: H0:pCA=pOR and HA:pCA≠pOR
# Since the data are randomly sampled, we can assume that the observations are independent. We need to recheck the success-failure condition using p̂ pool and expected counts. These are statisfied.

# Since the observations are independent and the success-failure condition is met, the difference in proportions is is expected to be approximately normal. The test statistics and p-value should be -1.68 and 0.093 respectively.

# Since the p-value > α, we fail to reject H0 and conclude that the data do not provide strong evidence that the rate of sleep deprivation is different for the two states.

# b) Type II, since we may have incorrectly failed to reject H0
```
    

## Submit

```{css echo=FALSE}
@media print {
  .topicsContainer,
  .topicActions,
  .exerciseActions .skip {
    display: none;
  }
  .topics .tutorialTitle,
  .topics .section.level2,
  .topics .section.level3:not(.hide) {
    display: block;
  }
  .topics {
    width: 100%;
  }
  .tutorial-exercise, .tutorial-question {
    page-break-inside: avoid;
  }
  .section.level3.done h3 {
    padding-left: 0;
    background-image: none;
  }
  .topics .showSkip .exerciseActions::before {
    content: "Topic not yet completed...";
    font-style: italic;
  }
}
```

Make sure you have the tutorial open in a browser (preferably Google Chrome). Please press `print page` button below to print the tutorial. Print it to a `pdf` file and upload it into Moodle. Make sure all code boxed are visible. If you can't do that please submit your answers to [the Google Form](https://forms.gle/iiVWeg5NjnhiQdrx5).

```{js print2pdf1, context="server"}
    // the following 2 chunks print the completed sections of the tutorial to PDF
    // uses "css/print2pdf.css"
    $(document).on('shiny:inputchanged', function(event) {
      if (event.name === 'print2pdf') {
        window.print();
      }
    });
```
    
```{r print2pdf2}
    # button can be placed anywhere in the tutorial
    actionButton("print2pdf", "Print page", style="opacity: .7; color: #000;")
```
